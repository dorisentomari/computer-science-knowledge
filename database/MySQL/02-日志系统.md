创建数据表 `mysql> create table T(ID int primary key, c int);`

给 ID = 2 的这一行值加 1 `mysql> update T set c=c+1 where ID = 2;`

分析器会通过词法和语法分析，知道这是一条更新语句，优化器要使用 ID 这个索引，之后，执行器负责具体执行，找到这一行，然后开始更新。

与查询流程不一样的是，更新流程还会有两个重要的日志模块，重做日志(redo log) 和归档日志(binlog)。

# 1. redo log

如果 MySQL 每日次更新操作都要写进磁盘，然后磁盘也要找到对应的那条记录，然后再进行更新，整个过程的 IO、查找成本都很高。所以 MySQL 采用了 WAL(Write-Ahead Logging) 技术，关键点是先写日志，再写磁盘，等到不忙的时候，再写磁盘。

具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候的更新就算是完成了。同时 InnoDB 会在恰当的时候，将这个操作记录更新到磁盘里，而这个更新往往是系统比较空闲的时候做。

InnoDB 引擎的 redo log 是固定大小的，所以当 redo log 空间被占满了之后，那么就要把数据写入磁盘，同时擦掉 redo log 对应的空间。

所以，有了 redo log，InnoDB 就可以保证即时数据库发生异常重启，之前提交的记录也不会丢失，这个能力称之为 crash-safe。

# 2. binlog

最开始 MySQL 是没有 InnoDB 引擎的，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。

# 3. redo log 和 binlog 的不同
+ redo log 是 InnoDB 引擎特有的，binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
+ redo log 是物理日志，记录的是“在某个数据页上做了什么修改”。而 binlog 日志记录的是这个语句的原始逻辑，比如 `给 ID=2 这一行的 c 字段加 1`。
+ redo log 是循环写的，空间固定会用完。binlog 是可以追加写入的。“追加写” 是指 binlog 文件写到一定大小后切换下一个，并不会覆盖以前的日志。

# 4. 再看 update 语句的内部流程

+ 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器。否则需要先从磁盘读入内存，然后再返回。
+ 执行器拿到引擎给的行数据，把这个值加上 1。得到新一行的数据，再调用引擎接口写入这行的新数据。
+ 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 中，此时 redo log 处于 prepare 的状态。然后告知执行器执行完了，随时可以提交事务。
+ 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
+ 执行器调用引擎的提交事务接口，引擎把刚写入的 redo log 改成提交 commit 状态，更新完成。

# 5. 两个阶段提交

binlog 会记录所有的逻辑操作，并且是采用追加写的形式。如果说数据可以在半年内恢复，那么备份系统中一定会保存最近半年所有的 binlog，同时系统会定期做整库备份。这里的定期取决于系统的重要性，可能是一天一备，可能是一周一备。

当需要恢复到指定的某一秒时，需要找回数据，需要这么操作：
+ 找到最近一次的全量备份，从这个备份恢复到临时库。
+ 从备份的时间点开始，将备份的 binlog 依次取出来，重放到误删表之前的那个时刻。

**为什么需要两个提交阶段？**

由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。

+ **先写 redo log 再写 binlog**。假设在 redo log 写完，binlog 还没有开始写的时候，MySQL 进程异常重启。之前说的，redo log
 写完之后，系统即使崩溃，依然能够把数据恢复过来，所以恢复后的这一行 c 的值就是 1。但是由于 binlog 还没写完就 crash 了，这时候 binlog 里没有记录这条语句。因此，之后备份日志的时候，存起来的 binlog 里就没有这条语句。但是如果要是用 binlog 来恢复临时库的话，由于这个语句的 binlog 缺失，就少了一次更新，恢复出来的这一行 c 的值就是 0。

+ **先写 binlog 后再写 redo log**。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复之后这个事务无效，所以这一行的值是 0。但是 binlog 里已经记录了 “把c从0改为1” 这个日志。所以在之后用 binlog 来恢复的时候就多出一个事务来，恢复出来的这一行 c 的值就是 1。

不仅仅是误操作后需要用这个过程来恢复数据。当需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法是用全量备份加上应用 binlog 来实现，这个不一致会导致线上主从数据库不一致。

所以：redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失。

sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。

# 6. 总结

Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。

Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。

1.首先客户端通过tcp/ip发送一条sql语句到server层的SQL interface

2.SQL interface接到该请求后，先对该条语句进行解析，验证权限是否匹配

3.验证通过以后，分析器会对该语句分析,是否语法有错误等

4.接下来是优化器器生成相应的执行计划，选择最优的执行计划

5.之后会是执行器根据执行计划执行这条语句。在这一步会去open table,如果该table上有MDL，则等待。如果没有，则加在该表上加短暂的MDL(S)(如果opend_table太大,表明open_table_cache太小。需要不停的去打开frm文件)

6.进入到引擎层，首先会去innodb_buffer_pool里的data dictionary(元数据信息)得到表信息

7.通过元数据信息,去lock info里查出是否会有相关的锁信息，并把这条update语句需要的锁信息写入到lock info里(锁这里还有待补充)

8.然后涉及到的老数据通过快照的方式存储到innodb_buffer_pool里的undo page里,并且记录undo log修改的redo (如果data page里有就直接载入到undo page
里，如果没有，则需要去磁盘里取出相应page的数据，载入到undo page里)

9.在innodb_buffer_pool的data page做update操作。并把操作的物理数据页修改记录到redo log buffer里，由于update这个事务会涉及到多个面的修改，所以redo log buffer 里会记录多条页面的修改信息。因为group commit的原因，这次事务所产生的redo log buffer可能会跟随其它事务一同flush并且sync到磁盘上

10.同时修改的信息，会按照event的格式,记录到binlog_cache中。(这里注意binlog_cache_size是transaction级别的,不是session级别的参数,一旦commit之后，dump线程会从binlog_cache里把event主动发送给slave的I/O线程)

11.之后把这条sql,需要在二级索引上做的修改，写入到change buffer page，等到下次有其他sql需要读取该二级索引时，再去与二级索引做merge(随机I/O变为顺序I/O,但是由于现在的磁盘都是SSD,所以对于寻址来说,随机I/O和顺序I/O差距不大)

12.此时update语句已经完成，需要commit或者rollback。这里讨论commit的情况，并且双1

13.commit操作，由于存储引擎层与server层之间采用的是内部XA(保证两个事务的一致性,这里主要保证redo log和binlog的原子性),所以提交分为prepare阶段与commit阶段

14.prepare阶段,将事务的xid写入，将binlog_cache里的进行flush以及sync操作(大事务的话这步非常耗时)

15.commit阶段，由于之前该事务产生的redo log已经sync到磁盘了。所以这步只是在redo log里标记commit

16.当binlog和redo log都已经落盘以后，如果触发了刷新脏页的操作，先把该脏页复制到doublewrite buffer里，把doublewrite buffer里的刷新到共享表空，然后才是通过page cleaner线程把脏页写入到磁盘中